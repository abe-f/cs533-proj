Reducing the cache capacity to <512MB doesn't really make sense, as there is 512MiB of L2 in the system, and (I believe?) ZSim models an inclusive LLC.

Plan is to run a sweep from .75GiB to 2GiB LLC size (by varying the number of ways)

1. Just increase the number of ways by 10%, which is the best case scenario (but realistic for single-threaded applications).
2. Collect statistics about (1) the number of sharers for all cache lines, and (2) number of sets in the cache that have all cache lines with 0 or 1 sharers

With zsim, we can demarcate regions of interest with these functions:
zsim_roi_begin();
zsim_roi_end();

We get these from zsim_hooks.h, and 

#include "zsim_hooks.h"

within the benchmark

GAPBS Benchmarks:
BFS (Breadth First Search)
    ./bfs -f /dataset/twitter_graph/twitter.el
SSSP (Single Source Shortest Path)
    ./sssp -f /dataset/twitter_graph/twitter.el
PR (PageRank)
    ./pr -f /dataset/twitter_graph/twitter.el
    - note: iteration time is 14s.
BC (Betweenness Center)
    ./bc -f /dataset/twitter_graph/twitter.el -n 1
    - note: iteration time is 5 seconds.
TC (Triangle Count) (need to use -sf for graph input)
    ./tc -sf /dataset/twitter_graph/twitter.el
    - note: one iteration of tc takes 100 minutes native on a 32-core machine. Maybe skip this for simulation, or find a smaller graph.

python3 run_sequential.py &> run_script_out.log &