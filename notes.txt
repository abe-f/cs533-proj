Reducing the cache capacity to <512MB doesn't really make sense, as there is 512MiB of L2 in the system, and (I believe?) ZSim models an inclusive LLC.

Plan is to run a sweep from .75GiB to 2GiB LLC size (by varying the number of ways)

1. Just increase the number of ways by 10%, which is the best case scenario (but realistic for single-threaded applications).
2. Collect statistics about (1) the number of sharers for all cache lines, and (2) number of sets in the cache that have all cache lines with 0 or 1 sharers

With zsim, we can demarcate regions of interest with these functions:
zsim_roi_begin();
zsim_roi_end();

We get these from zsim_hooks.h, and 

#include "zsim_hooks.h"

within the benchmark

GAPBS Benchmarks:
BFS (Breadth First Search)
    ./bfs -f /dataset/twitter_graph/twitter.el
SSSP (Single Source Shortest Path)
    ./sssp -f /dataset/twitter_graph/twitter.el
PR (PageRank)
    ./pr -f /dataset/twitter_graph/twitter.el
    - note: iteration time is 14s.
BC (Betweenness Center)
    ./bc -f /dataset/twitter_graph/twitter.el -n 1
    - note: iteration time is 5 seconds.
TC (Triangle Count) (need to use -sf for graph input)
    ./tc -sf /dataset/twitter_graph/twitter.el
    - note: iteration time is 100 minutes (native on a 32-core machine). Maybe skip this for simulation, or find a smaller graph.

python3 run_sequential.py -u &> run_script_out.log &
python3 run_parallel.py -u &> run_script_out.log &

killall "bc" # to kill processes

On vscode, just try running the ipynb file and install everything it tells you to

I believe that statsPhaseInterval is the number of phases per period stats dump. You can see how many phases were simulated with the 'phase' stat.

f["stats"]["root"] in python is an ndarray. You can see the indices with dset.dtype.names.

export OMP_NUM_THREADS=256 to change number of threads available for openmp


Stat we want:
For limited ptr cache with 8 lim ptr:
    Periodically, loop through all the sets in the cache, and count the number of sets with 1 or fewer sharers for each line. Store this in a 32b number.

For full bit-vector cache (256 bits per dir entry):
    Can dump 256 buckets, where there is one bucket per sharer number

Can motivate the idea with a 2D axis: one dimension is increasing or decreasing the number of directory entries, capped at 1X, and the
other dimension is the number of sharers. OR a 3D axis, where the other dimension is the cache capacity. Our solution gets the best of all worlds.